"""
These classes grab exploit code weight data from the following sources:
-ExploitDB
-Metasploit
-EPSS
-KEV
-Github
-Nuclei
-Packet Storm
-Google Project Zero
-Vulncheck
Thank you to t0sche for the inspiration:
https://github.com/t0sche/cvss-bt/blob/main/code/enrich_nvd.py
"""

import pandas as pd
import requests
import json
import gzip
import logging
import base64
import git
import os
import vulncheck_sdk
import zipfile
import re
from .get_retry import Retry
# from get_retry import Retry
from datetime import date, timedelta
from io import BytesIO, StringIO
from multiprocessing import Pool


# Foundational class for exploit dataframes
class CVEDataFrame:

    # Store dataframe given as argument
    def __init__(self, df, data_date):
        if not df.empty:
            self._df = df
        else:
            raise FileNotFoundError(f"Dataframe is empty")
        self._data_date = data_date

    # Function to make get request - implements Retry from get_retry.py
    @staticmethod
    def get_request(url, headers=None, params=None):
        res = requests.get(url, headers=headers)
        res = Retry.check_for_retries(res, params, headers, url)
        if res.status_code == 200:
            logging.info("Received response from get request")
        return res

    # Function to return if date of dataframe is today
    def df_up_to_date(self):
        return date.today() == self._data_date

    # Function for querying if CVE exists in dataframe
    def query_for_cve(self, cve):
        try:
            result = self._df.query(f'cve == "{cve}"')
            if not result.empty:
                return result
            else:
                return False
        except Exception as e:
            raise FileNotFoundError(f"{e}: Cannot query")

    # Function to return df
    def all_df_data(self):
        return self._df

    # Function to return date of data
    def data_date(self):
        return self._data_date


class KevDataFrame(CVEDataFrame):

    # Query for KEV data upon init
    def __init__(self):

        try:
            # API call to get KEV list
            logging.info("Grabbing KEV Catalogue")
            url = "https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json"
            headers = {"Content-Type": "application/json"}
            response = KevDataFrame.get_request(url, headers=headers)
            response = json.loads(response.text)
            # Parse through response
            kev_df = {'CVE_ID': [],
                      'KEV': [],
                      'Ransomware_Affiliation': []
                      }
            for cve in response['vulnerabilities']:
                kev_df['CVE_ID'].append(cve['cveID'])
                kev_df['KEV'].append(1)
                ransomware_affiliation = cve['knownRansomwareCampaignUse']
                if ransomware_affiliation == 'Known':
                    kev_df['Ransomware_Affiliation'].append(1)
                else:
                    kev_df['Ransomware_Affiliation'].append(0)

        except Exception as e:
            logging.info(f"{e}: Failed to get KEV Catalogue")

        # Store DF
        try:
            kev_df = pd.DataFrame(kev_df)
        except Exception as e:
            raise RuntimeError(f"{e}: Cannot convert to dataframe")

        # Store date of query
        data_date = response['catalogVersion'].replace('.', '-')

        # Init the parent class
        super().__init__(kev_df, data_date)

    # Function to check ransomware status
    def ransomware_affiliation(self, cve):
        row = self.query_for_cve(cve)
        if not row.empty:
            return row['Ransomware_Affiliation'].to_numpy()[0]
        else:
            return False


# EPSS Dataframe class
class EPSSDataFrame(CVEDataFrame):

    # Query for EPSS Data upon init
    def __init__(self):

        # API call to get complete EPSS csv
        try:
            # Make the call, decode bytes
            logging.info("Grabbing EPSS list from Cyentia")
            query_date = date.today()
            epss_request = requests.get(f'http://epss.cyentia.com/epss_scores-{query_date}.csv.gz').content
            epss_request = BytesIO(epss_request)
            # Convert to df
            epss_df = pd.read_csv(
                epss_request,
                compression='gzip',
                comment='#'
            )
            epss_df.rename(columns={'cve': 'CVE_ID', 'epss': 'EPSS',
                                    'percentile': 'EPSS_Percentile'}, inplace=True)
            
            # Make sure EPSS is a float
            epss_df['EPSS'] = epss_df['EPSS'].astype(float)

            epss_df['EPSS_Percentile'] = (epss_df['EPSS_Percentile'] * 100).apply(lambda x: f"{x:.2f}%")

            # Make a column for EPSS if it is above the threshold
            epss_df['EPSS_Above_Threshold'] = epss_df['EPSS'] >= 0.4

        # If EPSS data from Cyentia is not ready for today, query for day before
        except Exception as e:
            # Make the call, decode bytes
            query_date = date.today() - timedelta(days=1)
            epss_request = CVEDataFrame.get_request(
                f'http://epss.cyentia.com/epss_scores-{query_date}.csv.gz').content

            # Convert to df
            epss_request = BytesIO(epss_request)
            epss_df = pd.read_csv(
                epss_request,
                compression='gzip',
                comment='#'
            )
            epss_df.rename(columns={'cve': 'CVE_ID', 'epss': 'EPSS',
                                        'percentile': 'EPSS_Percentile'}, inplace=True)
            epss_df['EPSS_Percentile'] = (epss_df['EPSS_Percentile'] * 100).apply(lambda x: f"{x:.2f}%")
            epss_df['EPSS_Above_Threshold'] = epss_df['EPSS'] >= 0.4


        # init parent class
        logging.info(f"Retrieved EPSS data from {query_date}")
        super().__init__(epss_df, query_date)

    # Function to query EPSS, if not in EPSS return 0
    def epss_score(self, cve):
        row = self.query_for_cve(cve)
        if not row.empty:
            return row['epss'].to_numpy()[0]
        return None


# ExploitDB Dataframe class
class ExploitDBDataFrame(CVEDataFrame):

    # Query for EPSS data upon init
    def __init__(self):
        # Get csv from gitlab, alter csv row
        try:
            logging.info("Grabbing exploitDB CSV file")
            exploitdb_request = CVEDataFrame.get_request(
                'https://gitlab.com/exploit-database/exploitdb/-/raw/main/files_exploits.csv'
            ).content
            exploitdb_request = BytesIO(exploitdb_request)
            exploitdb_df = pd.read_csv(
                exploitdb_request,
                usecols=['codes']
            )

            # Only grab codes column, rename as cve
            exploitdb_df = exploitdb_df.rename(columns={"codes": "cve"})

            # Drop duplicates, extract CVEs. Borrowed from t0sche (see description)
            exploitdb_df.drop_duplicates(inplace=True)
            exploitdb_df = exploitdb_df['cve'].str.extract(r"(CVE-\d{4}-\d{4,7})", expand=False).dropna().values
            exploitdb_df = pd.DataFrame(exploitdb_df, columns=['CVE_ID'])
            exploitdb_df['ExploitDB'] = 1

        except Exception as e:
            raise ProcessLookupError(f"{e}: Not able to query ExploitDB Catalogue")

        # Set query date
        query_date = date.today()

        # init parent class
        super().__init__(exploitdb_df, query_date)


# Metasploit Dataframe class
class MetasploitDataFrame(CVEDataFrame):

    # Query for Metasploit data upon init
    def __init__(self):
        try:
            logging.info("Grabbing Metasploit module list")
            # url = 'https://raw.githubusercontent.com/rapid7/metasploit-framework/master/db/modules_metadata_base.json'
            # headers = {"Content-Type": "application/json"}
            # response = CVEDataFrame.get_request(url, headers=headers)
            # h = requests.head('https://raw.githubusercontent.com/rapid7/metasploit-framework/master/db/modules_metadata_base.json')
            # header = h.headers
            # logging.info(f'Headers: {header}')
            # test = response.text
            # logging.info(f'Response: {test}')
            url = 'https://api.github.com/repos/rapid7/metasploit-framework/contents/db/modules_metadata_base.json'
            headers = {"Accept": "application/vnd.github+json"}
            response = requests.get(url, headers=headers)
            git_url = response.json()["git_url"]
            response = requests.get(git_url, headers=headers).json()["content"]
            decoded_response = base64.b64decode(response).decode('utf-8')
            ip = requests.get('https://ifconfig.me').text
            logging.info(f'Querying IP: {ip}')
            response = json.loads(decoded_response)
        except Exception as e:
            logging.error(decoded_response)
            raise ProcessLookupError(f"{e}: Not able to query Metasploit list")

        # Format response, input to df. Thank you to t0sche again
        metasploit_list = []
        for item in response:
            if 'references' in response[item]:
                cve_references = [ref for ref in response[item]['references'] if ref.startswith('CVE-')]
                metasploit_list.extend(cve_references)
        metasploit_df = pd.DataFrame(metasploit_list, columns=['CVE_ID'])
        metasploit_df['Metasploit_Module'] = 1

        # Set date, init parent class
        query_date = date.today()
        super().__init__(metasploit_df, query_date)

# MetasploitDataFrame()

# GitHub Dataframe class
class GithubDataFrame(CVEDataFrame):

    # Query for GitHub data upon init
    def __init__(self):

        # Download the Github Trickest Repo
        repo_url = "https://github.com/trickest/cve.git"
        target_directory = f"cve_repo_{date.today()}"
        try:
            git.Repo.clone_from(repo_url, target_directory)
            print(f"Successfully cloned {repo_url} to {target_directory}")
        except git.GitCommandError as e:
            print(f"Error cloning {repo_url}: {e}")
        except Exception as e:
            print(f"An error occurred while cloning {repo_url}: {str(e)}")
        
        # Store result of CVEs in list
        # directory = "./cve_repo"
        github_list = self.process_directory(target_directory)  

        # Convert to df
        github_df = pd.DataFrame(github_list, columns=['CVE_ID'])
        github_df['POC_In_Github'] = 1

        # Set date, init parent class
        query_date = date.today()
        super().__init__(github_df, query_date)
    
    # Worker function to delete files without a CVE_ID within the sources section
    def delete_md_file_without_cve_id(self, file_path):

        # Variable for storing the end result
        remaining_files = []

        # Only grab .md files that end with an .md and are within the year folder
        if file_path.endswith(".md"):
            year = os.path.basename(os.path.dirname(file_path))
            if year.isdigit() and len(year) == 4:
                with open(file_path, "r") as f:
                    content = f.read()

                # Grab the github links, ignore everything else
                github_header_match = re.search(r"#### Github\s*-\s*((.|\n)*)", content, re.IGNORECASE | re.MULTILINE)
                if github_header_match:
                    github_content = github_header_match.group(1)

                    # Make sure the CVE grabbed matches the filename CVE
                    cve_id_match = re.search(r"CVE-\d{4}-\d+", github_content)
                    filename_cve_id = os.path.splitext(os.path.basename(file_path))[0]
                    no_pocs_found_match = re.search(r"No PoCs found on GitHub currently\.", content)
                    
                    # Only add it to the list/keep file if the CVE matches the filename
                    if cve_id_match and cve_id_match.group(0) == filename_cve_id and not no_pocs_found_match:
                        remaining_files.append(cve_id_match.group(0))
                    
                    # Delete if it does not
                    else:
                        logging.info(f"Deleting {file_path} because CVE ID in filename does not match the CVE ID in content or 'No PoCs found on GitHub currently.' is present.")
                        os.remove(file_path)
                else:
                    logging.info(f"Deleting {file_path} because CVE ID in filename does not match the CVE ID in content or 'No PoCs found on GitHub currently.' is present.")
                    os.remove(file_path)
        return remaining_files
    
    # Use the worker function and multiprocess the results
    def process_directory(self, directory):
        remaining_files = []

        # Set processes as 8 for now
        with Pool(processes=8) as pool:
            results = pool.map(self.delete_md_file_without_cve_id, [os.path.join(root, file) for root, dirs, files in os.walk(directory) for file in files])
            for result in results:
                remaining_files.extend(result)
        return remaining_files


# GoogleProjectZero Dataframe class
class GoogleProjectZero(CVEDataFrame):

    # Query for GitHub data upon init
    def __init__(self):

        # Grab all CVEs in the trickest GitHub repo
        try:
            logging.info("Grabbing GoogleProjectZero analysis list")
            url = 'https://api.github.com/repos/googleprojectzero/0days-in-the-wild/git/trees/main?recursive=1'
            headers = {"Content-Type": "application/json"}
            response = CVEDataFrame.get_request(url, headers=headers)
            response = json.loads(response.text)
        except Exception as e:
            raise ProcessLookupError(f"{e}: Not able to query Github list")

        # Format response, input to df
        github_list = []
        for item in response['tree']:
            if item.get('path'):

                # Regex for CVE ID. If ID, add to GitHub list
                cve_id = re.findall(r'CVE-\d{4}-\d*', item['path'])
                if cve_id:
                    github_list.append(cve_id[0])

        # Convert to df
        github_df = pd.DataFrame(github_list, columns=['CVE_ID'])
        github_df['Google_Project_Zero'] = 1

        # Set date, init parent class
        query_date = date.today()
        super().__init__(github_df, query_date)



# Nuclei Dataframe class
class NucleiDataFrame(CVEDataFrame):

    # Grab data from Nuclei. Thank you again t0sche
    def __init__(self):
        logging.info("Grabbing Nuclei CVE list")
        # url = 'https://raw.githubusercontent.com/projectdiscovery/nuclei-templates/main/cves.json'
        # headers = {"Content-Type": "application/json"}
        # response = CVEDataFrame.get_request(url, headers=headers)
        # response = response.text
        url = 'https://api.github.com/repos/projectdiscovery/nuclei-templates/contents/cves.json'
        headers = {"Accept": "application/vnd.github+json"}
        response = requests.get(url, headers=headers)
        git_url = response.json()["git_url"]
        response = requests.get(git_url, headers=headers).json()["content"]
        decoded_response = base64.b64decode(response).decode('utf-8')

        # Nuclei response formats each entry as its own dictionary. Just throw in the response as a df
        nuclei_df = pd.read_json(decoded_response, lines=True)
        nuclei_df.rename(columns={"ID": "CVE_ID"}, inplace=True)
        nuclei_df = nuclei_df.drop(columns=['Info', 'file_path'])
        nuclei_df['Nuclei'] = 1

        # Set date, init parent class
        query_date = date.today()
        super().__init__(nuclei_df, query_date)


# Vulncheck Dataframe class
class VulncheckDataFrame(CVEDataFrame):

    # Grab data from Nuclei. Thank you again t0sche
    def __init__(self, vulncheck_secret):
        configuration = vulncheck_sdk.Configuration(host="https://api.vulncheck.com/v3")
        configuration.api_key["Bearer"] = vulncheck_secret

        with vulncheck_sdk.ApiClient(configuration) as api_client:
            endpoints_client = vulncheck_sdk.EndpointsApi(api_client)

            if not os.path.isdir('./vulncheck_kev_file'):
                os.mkdir('vulncheck_kev_file')
            index = "vulncheck-kev"

            api_response = endpoints_client.backup_index_get(index)

            backup_url = requests.get(api_response.data[0].url)

            file_path = f"./vulncheck_kev_file/{index}.zip"
            with open(file_path, "wb") as file:
                file.write(backup_url.content)
            
            with zipfile.ZipFile(file_path, 'r') as zip_ref:
                zip_ref.extractall(path='./vulncheck_kev_file/')

                # Read the JSON file
                with open('./vulncheck_kev_file/vulncheck_known_exploited_vulnerabilities.json', 'r') as json_file:
                    data = json.load(json_file)
                    cve_list = []

                    # Extract all CVEs from the JSON data
                    for item in data:

                        # Add cves to a list if they exist in the JSON data
                        if item.get('cve') != []:
                            for cve in item['cve']:
                                cve_list.append(cve)
                        # print(json.dumps(item, indent=4))
                        # quit()
            
            # Put into set then list so that no duplicates are returned
        vulncheck_list = list(set(cve_list))
        vulncheck_df = pd.DataFrame(vulncheck_list, columns=['CVE_ID'])
        vulncheck_df['Vulncheck_KEV'] = 1

        # Set date, init parent class
        query_date = date.today()
        super().__init__(vulncheck_df, query_date)
